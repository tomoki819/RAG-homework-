# RAG -homework-
本リポジトリはAIエンジニアリング実践講座のDay3のためのリポジトリになります。
Day3のHomeworkは、独自の質問・データセットを用意してRAGの効果を検証する流れをより深く理解するために行います。
このHomeworkの目的を達成するために私が用意した質問が以下の通りです。

## 質問設計の背景
ここでは、私が注目している**磯村拓哉先生**に関する質問を作ろうと思います。なぜ磯村拓哉先生に注目するかというと、私は脳を数理モデルで説明できるという自由エネルギー原理に2025年3月に感銘を受けて、2018年に磯村拓哉先生の
[自由エネルギー原理の解説：知覚・行動・他者の思考の推論](https://www.jstage.jst.go.jp/article/jnns/25/3/25_71/_pdf/-char/ja)という論文を読みました。また、同級生で脳の研究を先進的に取り組まれている苅山くんに話を聞いたところ。「磯村先生すごいよ」という話を聞きました。

そして最近2025年4月17日に磯村拓哉先生が理化学研究所から[**脳知能の三大理論を統合する三重等価性**](https://www.riken.jp/press/2025/20250417_1/index.html)という研究のプレスリリースを発表されていました。
すごい研究をなさっていると感銘を受けたので、「ChatGPT-4o」に「**磯村拓哉ユニットリーダーが、2025年に発表した研究は何？**」と質問をしたところ

>「現在のところ、2025年に磯村拓哉ユニットリーダーが発表した研究に関する具体的な情報は確認できません。磯村拓哉氏が所属する理化学研究所 生命機能科学研究センター（BDR）では、生命科学分野における多岐にわたる研究が行われており、各ユニットリーダーがそれぞれの専門分野で研究を進めています。磯村氏の研究内容や発表についての詳細を知るには、理化学研究所の公式ウェブサイトやBDRの研究者紹介ページ、または関連する学術論文データベースを参照することをおすすめします。」

というような回答が返ってきて、この磯村拓哉先生が新しく発表された研究についてLLM単体では知らないし、web検索機能を使っても知ることができていないことがわかりました。

以上のことから、Day3のHomeworkでは、磯村拓哉先生が発表された[**脳知能の三大理論を統合する三重等価性**](https://www.riken.jp/press/2025/20250417_1/index.html)についての質問を作ろうと思います。

## 具体的な質問内容
具体的な質問を5つ考えました。

**1, 磯村拓哉ユニットリーダーの論文「脳知能の三大理論を統合する三重等価性」の要約をしてください**

**2, 論文「脳知能の三大理論を統合する三重等価性」では、どのような研究目的があったのでしょうか？**

**3, 論文「脳知能の三大理論を統合する三重等価性」では、どのような仮説を立てたのでしょうか？**

**4, 論文「脳知能の三大理論を統合する三重等価性」では、どのような考察をされているのでしょうか？**

**5, 論文「脳知能の三大理論を統合する三重等価性」では、どのような文献を参考にしているのでしょうか？**


## RAGに読み込ませる参考資料
RAGに対して読み込ませる参考資料ですが、2つの資料を採用したいと思います。

1つ目が[**本論文のプレスリリース**](https://www.riken.jp/press/2025/20250417_1/index.html)です。この資料を用いるのは、本資料が日本語で書かれていますし、プレスリリース用として非常にわかりやすい言葉で書いてくれているからです。また用語の解説もつけてくれています。なので、この資料は質問への回答をわかりやすくするために使えると考えます。

2つ目が[**原論文.pdf**](https://github.com/user-attachments/files/20028881/s42005-025-02059-4.pdf)です。この資料を用いることで、1つ目のプレスリリースではわからない情報や捕捉情報を知りたい時に、情報を提供できるのではないかと考えています。

ですので、結果的にではありますが、Day3の後半の講義資料で書かれていたDL基礎講座のChatBotのモデルの構造と類似しています。
![スクリーンショット 2025-05-05 2 48 49](https://github.com/user-attachments/assets/ed7ff13c-1f55-4384-8b76-262756f9f659)




### ベースラインモデルの結果と分析
ベースラインモデルを作成して、**「磯村拓哉ユニットリーダーの論文「脳知能の三大理論を統合する三重等価性」の要約をしてください」**という質問を入力したところ以下のような返答が返ってきました。

![スクリーンショット 2025-05-05 14 31 58](https://github.com/user-attachments/assets/4d16d29a-f9f7-4c81-9959-b915f996f0b6)

こちらの返答結果を以下の観点から評価する。

* 正確性: 回答が事実と一致しているか(0-5点)

* 完全性: 質問に対する必要な情報がすべて含まれているか(0-5点)

* 関連性: 回答が質問に適切に対応しているか(0-5点)

* 自動評価: LLMによるYes/No評価や数値評価の設計


正確性：0点、完全性：0点、関連性：0点で、LLMにより自動評価をさせたところ以下のようになった。

![スクリーンショット 2025-05-05 14 59 28](https://github.com/user-attachments/assets/24112d35-bdbd-4c9c-8b90-8a2d7664531c)

自動評価では、評価0~5の内4と評価しており、事実誤認であることを認識できることなく評価しているみたいだ。つまり、LLMに知識がなければ回答の評価すらも間違ってしまうということがわかった。


### 知識の導入(RAG.v1)
ではここからRAGのV1を作っていく。v1では、まず質問とプレスリリース資料との類似度を検索をして、その検索結果と質問を使って要約を作成して、次にその要約と質問をもとに、原著論文との類似度を検索をして、最終的な解答を出す、というモデルで作る。このモデル構造は、まさにDL基礎講座のChatBot構造と同じである。
このRAGでの実装結果は以下の通りだ。


「質問: 磯村拓哉ユニットリーダーの論文「脳知能の三大理論を統合する三重等価性」の要約をしてください」

→磯村ユニットリーダーは、脳知能の三大理論（canonical neural networks、variational Bayesian inference、differentiable Turing machines）を統合する三重等価性を示しました。この等価性は、脳の神経回路の dynamical systemと、統計的/ベイズ的推論を行う神経回路の agents、そして計算を行う機械を統合するものです。


「質問: 論文「脳知能の三大理論を統合する三重等価性」では、どのような研究目的があったのでしょうか？」

→論文では、脳知能の三大理論（ニューラルネットワーク、ベイジアン推論、 and Turing machine）を統合し、その統合における等価性を検証することを目的としています。


「質問: 論文「脳知能の三大理論を統合する三重等価性」では、どのような仮説を立てたのでしょうか？」

→論文では、脳知能の三大理論を統合する「三重等価性」を提案しました。


「質問：論文「脳知能の三大理論を統合する三重等価性」では、どのような考察をされているのでしょうか？」

→この論文では、脳知能を理解するための３つの主要な理論（進化論、神経科学、情報理論）を統合し、それぞれが他の理論とどのように関連しているかを考察しています。具体的には、進化論から生じる生物的アルゴリズムが、神経科学と情報理論の枠組みでどのように表現されるのかを明らかにしています。


「質問：論文「脳知能の三大理論を統合する三重等価性」では、どのような文献を参考にしているのでしょうか？」

→* 19: Causal inference,22: Rule learning,20: Planning,23, 24, 25: In vitro neural networks



以上の結果を分析すると、論文の中に使われている用語をもとに回答が使われていることが見て取れる。例えば、一問目の質問である要約に対して、「canonical neural networks、variational Bayesian inference、differentiable Turing machines」という、原著論文で書かれていた内容をそのまま答えることができている。そういう意味で、全ての質問の正確性は3点。続いて完全性という点においては、すべて情報が不足している。もっと説明があってもいいと思います。なので完全性は1点。関連性という点においては、どれも関連した内容を答えられているが、質問が違うことによる回答の内容に大きく違いが出ていないことを鑑みると、もっと関連性は出せるのかなと思います。なので関連性は2点。最後にLLMによる自動評価ですが、こちらは採用しません。なぜなら関連しうるかどうかを判断するLLMがこれらの知識を持っている必要があるので。。


以上の分析結果からプレスリリースと原著論文の検索を直列にしたことの弊害が少し見られているように見える。そこで、v2ではプレスリリースのみからの回答、v3では原著論文のみからの回答、v5では2つの資料から並列して回答させてみる。

### 知識の導入(RAG.v2)



